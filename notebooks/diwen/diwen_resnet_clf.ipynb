{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import os\n",
    "import sys\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from easydict import EasyDict as edict\n",
    "import json\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "random_seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimic = 0\n",
    "m = 10000\n",
    "n = 20000\n",
    "t = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,t):\n",
    "        super().__init__()\n",
    "        self.res = models.resnet152(pretrained=True)\n",
    "        num_ftrs = self.res.fc.in_features\n",
    "        self.res.fc = nn.Linear(num_ftrs, t)\n",
    "\n",
    "        self.linear = nn.Linear(t, 1)\n",
    "        \n",
    "        self.norm = nn.LayerNorm(t)\n",
    "        \n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.res(x))\n",
    "        x = self.leaky_relu(self.norm(x))\n",
    "        x = self.leaky_relu(self.linear(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19 = models.vgg19(pretrained=True)\n",
    "# mod = list(vgg19.classifier.children())\n",
    "# mod.pop()\n",
    "# mod.append(torch.nn.Linear(4096, 1024))\n",
    "# mod.append(torch.nn.Linear(1024, 256))\n",
    "# mod.append(torch.nn.Linear(256, 1))\n",
    "# new_classifier = torch.nn.Sequential(*mod)\n",
    "# vgg19.classifier = new_classifier\n",
    "# model = vgg19.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train':\n",
    "    transforms.Compose(\n",
    "        [\n",
    "#             transforms.ToPILImage(),\n",
    "            transforms.Resize((256,256)),\n",
    "            transforms.RandomResizedCrop((224),scale=(0.9,1)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "#             transforms.RandomCrop(32, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "        ]),\n",
    "    'val':\n",
    "    transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_mimic_train_path = '/shared/rsaas/nschiou2/CXR/data/train/mimic'\n",
    "real_chexpert_train_path = '/shared/rsaas/nschiou2/CXR/data/train/chexpert'\n",
    "real_mimic_test_path = '/shared/rsaas/nschiou2/CXR/data/test/mimic'\n",
    "real_chexpert_test_path = '/shared/rsaas/nschiou2/CXR/data/test/chexpert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syn = datasets.ImageFolder('/home/diwenxu2/data_v3/train/syn', transform=transform['train'])\n",
    "real_mimic = datasets.ImageFolder(real_mimic_train_path, transform=transform['train'])\n",
    "chexpert = datasets.ImageFolder(real_chexpert_train_path, transform=transform['train'])\n",
    "# syn_chexpert = datasets.ImageFolder('/home/diwenxu2/syn_chex', transform=transform['train'])\n",
    "mimic_test = datasets.ImageFolder(real_mimic_test_path, transform=transform['val'])\n",
    "# comb = datasets.ImageFolder('/shared/rsaas/diwenxu2/data_v3/train/comb', transform=transform['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_c = np.arange(len(real_mimic))\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(index_c)\n",
    "# index_s = np.arange(len(syn))\n",
    "# np.random.seed(random_seed)\n",
    "# np.random.shuffle(index_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mimic:\n",
    "#     m = n-20\n",
    "    \n",
    "# else:\n",
    "#     m = n\n",
    "# m = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected = data_utils.Subset(chexpert, index[:m])\n",
    "# selected = data_utils.Subset(syn_chexpert, index[:m])\n",
    "# selected = data_utils.Subset(syn, index[:m])\n",
    "# selected = data_utils.Subset(chexpert, index[:m])\n",
    "# data_syn = data_utils.Subset(syn, index_s[:m])\n",
    "data_chex = data_utils.Subset(chexpert,index_c[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mimic:\n",
    "#     dataset = torch.utils.data.ConcatDataset([chexpert,selected])\n",
    "# else:\n",
    "#     dataset = selected\n",
    "# dataset = torch.utils.data.ConcatDataset([data_syn,data_chex])\n",
    "dataset = data_utils.Subset(real_mimic, index_c[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(dataset)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = int((total)/5*4)\n",
    "val = int(total-tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_set, va_set = torch.utils.data.random_split(dataset, [tra,val],generator=torch.Generator().manual_seed(random_seed))\n",
    "# tra_set = dataset\n",
    "# va_set = mimic_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {'train':len(tra_set),'val':len(va_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 16000, 'val': 4000}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(tra_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_set = torch.utils.data.DataLoader(va_set, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 250)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set),len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':train_set,'val':val_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            label_list = []\n",
    "            output_list = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.unsqueeze(1).to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.type_as(outputs)\n",
    "#                     _, preds = torch.max(outputs, 1)\n",
    "                    preds = torch.sigmoid(outputs)>0.5\n",
    "                    loss = criterion(torch.sigmoid(outputs), labels)\n",
    "                    \n",
    "                    for i in range(len(outputs)):\n",
    "                        output_list.append(torch.sigmoid(outputs[i]).cpu().data.numpy().tolist())\n",
    "                        label_list.append(labels[i].cpu().data.numpy().tolist())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "#             fpr, tpr, thresholds = metrics.roc_curve(np.array(label_list), np.array(output_list), pos_label=2)\n",
    "#             auc = metrics.auc(fpr, tpr)\n",
    "            auc = roc_auc_score(np.array(label_list),np.array(output_list))\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} AUC: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, auc))\n",
    "#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "#                 phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.6947 Acc: 0.5001 AUC: 0.6387\n",
      "val Loss: 0.6848 Acc: 0.4995 AUC: 0.7861\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.6454 Acc: 0.6597 AUC: 0.8097\n",
      "val Loss: 0.6116 Acc: 0.7592 AUC: 0.8662\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7726 AUC: 0.8679\n",
      "val Loss: 0.5997 Acc: 0.7895 AUC: 0.8862\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5975 Acc: 0.7949 AUC: 0.8800\n",
      "val Loss: 0.5960 Acc: 0.7848 AUC: 0.8855\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.5919 Acc: 0.8036 AUC: 0.8874\n",
      "val Loss: 0.5913 Acc: 0.8127 AUC: 0.8934\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.5892 Acc: 0.8135 AUC: 0.8909\n",
      "val Loss: 0.5912 Acc: 0.8153 AUC: 0.8888\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.5869 Acc: 0.8131 AUC: 0.8943\n",
      "val Loss: 0.5966 Acc: 0.7708 AUC: 0.8898\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.5846 Acc: 0.8083 AUC: 0.9002\n",
      "val Loss: 0.5893 Acc: 0.8115 AUC: 0.8955\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.5807 Acc: 0.8267 AUC: 0.9045\n",
      "val Loss: 0.5889 Acc: 0.8115 AUC: 0.8965\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.5798 Acc: 0.8303 AUC: 0.9051\n",
      "val Loss: 0.5856 Acc: 0.8207 AUC: 0.8996\n",
      "\n",
      "Training complete in 69m 17s\n",
      "Best val Acc: 0.820750\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 20.5120 Acc: 0.6707 AUC: 0.7614\n",
      "val Loss: 20.6878 Acc: 0.7265 AUC: 0.7888\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 20.6017 Acc: 0.6875 AUC: 0.7455\n",
      "val Loss: 21.0078 Acc: 0.6208 AUC: 0.7156\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 20.5911 Acc: 0.6756 AUC: 0.7283\n",
      "val Loss: 22.0233 Acc: 0.6668 AUC: 0.7060\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 20.4134 Acc: 0.7023 AUC: 0.7618\n",
      "val Loss: 20.2730 Acc: 0.7402 AUC: 0.7825\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 20.3392 Acc: 0.7181 AUC: 0.7670\n",
      "val Loss: 21.1782 Acc: 0.6302 AUC: 0.7310\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 20.1432 Acc: 0.7199 AUC: 0.7786\n",
      "val Loss: 19.8673 Acc: 0.7412 AUC: 0.8109\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 20.1472 Acc: 0.7167 AUC: 0.7719\n",
      "val Loss: 20.3524 Acc: 0.6757 AUC: 0.7900\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 20.1190 Acc: 0.6994 AUC: 0.7798\n",
      "val Loss: 19.8252 Acc: 0.7362 AUC: 0.8122\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 19.7819 Acc: 0.7407 AUC: 0.8159\n",
      "val Loss: 19.7045 Acc: 0.7418 AUC: 0.8223\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 19.6734 Acc: 0.7484 AUC: 0.8250\n",
      "val Loss: 19.5536 Acc: 0.7552 AUC: 0.8371\n",
      "\n",
      "Training complete in 62m 13s\n",
      "Best val Acc: 0.755250\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/299\n",
      "----------\n",
      "train Loss: 0.6120 Acc: 0.7540 AUC: 0.8321\n",
      "val Loss: 0.6103 Acc: 0.7568 AUC: 0.8305\n",
      "\n",
      "Epoch 1/299\n",
      "----------\n",
      "train Loss: 0.6125 Acc: 0.7575 AUC: 0.8303\n",
      "val Loss: 0.6089 Acc: 0.7698 AUC: 0.8339\n",
      "\n",
      "Epoch 2/299\n",
      "----------\n",
      "train Loss: 0.6104 Acc: 0.7656 AUC: 0.8342\n",
      "val Loss: 0.6080 Acc: 0.7770 AUC: 0.8379\n",
      "\n",
      "Epoch 3/299\n",
      "----------\n",
      "train Loss: 0.6105 Acc: 0.7660 AUC: 0.8351\n",
      "val Loss: 0.6071 Acc: 0.7770 AUC: 0.8423\n",
      "\n",
      "Epoch 4/299\n",
      "----------\n",
      "train Loss: 0.6101 Acc: 0.7666 AUC: 0.8366\n",
      "val Loss: 0.6054 Acc: 0.7782 AUC: 0.8410\n",
      "\n",
      "Epoch 5/299\n",
      "----------\n",
      "train Loss: 0.6083 Acc: 0.7706 AUC: 0.8399\n",
      "val Loss: 0.6070 Acc: 0.7840 AUC: 0.8401\n",
      "\n",
      "Epoch 6/299\n",
      "----------\n",
      "train Loss: 0.6081 Acc: 0.7720 AUC: 0.8408\n",
      "val Loss: 0.6051 Acc: 0.7853 AUC: 0.8451\n",
      "\n",
      "Epoch 7/299\n",
      "----------\n",
      "train Loss: 0.6067 Acc: 0.7752 AUC: 0.8432\n",
      "val Loss: 0.6068 Acc: 0.7715 AUC: 0.8448\n",
      "\n",
      "Epoch 8/299\n",
      "----------\n",
      "train Loss: 0.6080 Acc: 0.7722 AUC: 0.8427\n",
      "val Loss: 0.6055 Acc: 0.7790 AUC: 0.8467\n",
      "\n",
      "Epoch 9/299\n",
      "----------\n",
      "train Loss: 0.6066 Acc: 0.7755 AUC: 0.8432\n",
      "val Loss: 0.6061 Acc: 0.7752 AUC: 0.8464\n",
      "\n",
      "Epoch 10/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7758 AUC: 0.8442\n",
      "val Loss: 0.6061 Acc: 0.7758 AUC: 0.8468\n",
      "\n",
      "Epoch 11/299\n",
      "----------\n",
      "train Loss: 0.6052 Acc: 0.7774 AUC: 0.8459\n",
      "val Loss: 0.6038 Acc: 0.7818 AUC: 0.8446\n",
      "\n",
      "Epoch 12/299\n",
      "----------\n",
      "train Loss: 0.6060 Acc: 0.7766 AUC: 0.8445\n",
      "val Loss: 0.6068 Acc: 0.7770 AUC: 0.8469\n",
      "\n",
      "Epoch 13/299\n",
      "----------\n",
      "train Loss: 0.6069 Acc: 0.7745 AUC: 0.8440\n",
      "val Loss: 0.6033 Acc: 0.7855 AUC: 0.8478\n",
      "\n",
      "Epoch 14/299\n",
      "----------\n",
      "train Loss: 0.6059 Acc: 0.7767 AUC: 0.8444\n",
      "val Loss: 0.6073 Acc: 0.7762 AUC: 0.8412\n",
      "\n",
      "Epoch 15/299\n",
      "----------\n",
      "train Loss: 0.6064 Acc: 0.7746 AUC: 0.8444\n",
      "val Loss: 0.6055 Acc: 0.7732 AUC: 0.8494\n",
      "\n",
      "Epoch 16/299\n",
      "----------\n",
      "train Loss: 0.6072 Acc: 0.7737 AUC: 0.8443\n",
      "val Loss: 0.6057 Acc: 0.7830 AUC: 0.8438\n",
      "\n",
      "Epoch 17/299\n",
      "----------\n",
      "train Loss: 0.6058 Acc: 0.7769 AUC: 0.8447\n",
      "val Loss: 0.6061 Acc: 0.7825 AUC: 0.8472\n",
      "\n",
      "Epoch 18/299\n",
      "----------\n",
      "train Loss: 0.6068 Acc: 0.7742 AUC: 0.8444\n",
      "val Loss: 0.6055 Acc: 0.7778 AUC: 0.8450\n",
      "\n",
      "Epoch 19/299\n",
      "----------\n",
      "train Loss: 0.6072 Acc: 0.7725 AUC: 0.8440\n",
      "val Loss: 0.6053 Acc: 0.7810 AUC: 0.8476\n",
      "\n",
      "Epoch 20/299\n",
      "----------\n",
      "train Loss: 0.6078 Acc: 0.7726 AUC: 0.8430\n",
      "val Loss: 0.6046 Acc: 0.7785 AUC: 0.8460\n",
      "\n",
      "Epoch 21/299\n",
      "----------\n",
      "train Loss: 0.6045 Acc: 0.7784 AUC: 0.8459\n",
      "val Loss: 0.6051 Acc: 0.7760 AUC: 0.8457\n",
      "\n",
      "Epoch 22/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7762 AUC: 0.8432\n",
      "val Loss: 0.6062 Acc: 0.7778 AUC: 0.8476\n",
      "\n",
      "Epoch 23/299\n",
      "----------\n",
      "train Loss: 0.6057 Acc: 0.7764 AUC: 0.8463\n",
      "val Loss: 0.6054 Acc: 0.7775 AUC: 0.8443\n",
      "\n",
      "Epoch 24/299\n",
      "----------\n",
      "train Loss: 0.6071 Acc: 0.7731 AUC: 0.8441\n",
      "val Loss: 0.6048 Acc: 0.7863 AUC: 0.8487\n",
      "\n",
      "Epoch 25/299\n",
      "----------\n",
      "train Loss: 0.6065 Acc: 0.7751 AUC: 0.8448\n",
      "val Loss: 0.6063 Acc: 0.7675 AUC: 0.8467\n",
      "\n",
      "Epoch 26/299\n",
      "----------\n",
      "train Loss: 0.6067 Acc: 0.7740 AUC: 0.8437\n",
      "val Loss: 0.6043 Acc: 0.7785 AUC: 0.8488\n",
      "\n",
      "Epoch 27/299\n",
      "----------\n",
      "train Loss: 0.6054 Acc: 0.7768 AUC: 0.8454\n",
      "val Loss: 0.6064 Acc: 0.7742 AUC: 0.8456\n",
      "\n",
      "Epoch 28/299\n",
      "----------\n",
      "train Loss: 0.6069 Acc: 0.7744 AUC: 0.8437\n",
      "val Loss: 0.6016 Acc: 0.7893 AUC: 0.8490\n",
      "\n",
      "Epoch 29/299\n",
      "----------\n",
      "train Loss: 0.6056 Acc: 0.7772 AUC: 0.8435\n",
      "val Loss: 0.6055 Acc: 0.7810 AUC: 0.8468\n",
      "\n",
      "Epoch 30/299\n",
      "----------\n",
      "train Loss: 0.6066 Acc: 0.7744 AUC: 0.8452\n",
      "val Loss: 0.6040 Acc: 0.7825 AUC: 0.8478\n",
      "\n",
      "Epoch 31/299\n",
      "----------\n",
      "train Loss: 0.6059 Acc: 0.7754 AUC: 0.8474\n",
      "val Loss: 0.6041 Acc: 0.7810 AUC: 0.8483\n",
      "\n",
      "Epoch 32/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7755 AUC: 0.8456\n",
      "val Loss: 0.6061 Acc: 0.7760 AUC: 0.8444\n",
      "\n",
      "Epoch 33/299\n",
      "----------\n",
      "train Loss: 0.6063 Acc: 0.7752 AUC: 0.8442\n",
      "val Loss: 0.6040 Acc: 0.7790 AUC: 0.8486\n",
      "\n",
      "Epoch 34/299\n",
      "----------\n",
      "train Loss: 0.6055 Acc: 0.7776 AUC: 0.8468\n",
      "val Loss: 0.6055 Acc: 0.7770 AUC: 0.8455\n",
      "\n",
      "Epoch 35/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7761 AUC: 0.8450\n",
      "val Loss: 0.6042 Acc: 0.7818 AUC: 0.8488\n",
      "\n",
      "Epoch 36/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7756 AUC: 0.8437\n",
      "val Loss: 0.6051 Acc: 0.7768 AUC: 0.8475\n",
      "\n",
      "Epoch 37/299\n",
      "----------\n",
      "train Loss: 0.6053 Acc: 0.7776 AUC: 0.8462\n",
      "val Loss: 0.6053 Acc: 0.7782 AUC: 0.8472\n",
      "\n",
      "Epoch 38/299\n",
      "----------\n",
      "train Loss: 0.6068 Acc: 0.7729 AUC: 0.8434\n",
      "val Loss: 0.6058 Acc: 0.7828 AUC: 0.8443\n",
      "\n",
      "Epoch 39/299\n",
      "----------\n",
      "train Loss: 0.6077 Acc: 0.7718 AUC: 0.8439\n",
      "val Loss: 0.6059 Acc: 0.7828 AUC: 0.8466\n",
      "\n",
      "Epoch 40/299\n",
      "----------\n",
      "train Loss: 0.6059 Acc: 0.7759 AUC: 0.8459\n",
      "val Loss: 0.6044 Acc: 0.7785 AUC: 0.8457\n",
      "\n",
      "Epoch 41/299\n",
      "----------\n",
      "train Loss: 0.6064 Acc: 0.7753 AUC: 0.8459\n",
      "val Loss: 0.6078 Acc: 0.7780 AUC: 0.8453\n",
      "\n",
      "Epoch 42/299\n",
      "----------\n",
      "train Loss: 0.6066 Acc: 0.7749 AUC: 0.8446\n",
      "val Loss: 0.6076 Acc: 0.7710 AUC: 0.8436\n",
      "\n",
      "Epoch 43/299\n",
      "----------\n",
      "train Loss: 0.6072 Acc: 0.7739 AUC: 0.8437\n",
      "val Loss: 0.6058 Acc: 0.7800 AUC: 0.8481\n",
      "\n",
      "Epoch 44/299\n",
      "----------\n",
      "train Loss: 0.6054 Acc: 0.7768 AUC: 0.8452\n",
      "val Loss: 0.6057 Acc: 0.7732 AUC: 0.8435\n",
      "\n",
      "Epoch 45/299\n",
      "----------\n",
      "train Loss: 0.6070 Acc: 0.7736 AUC: 0.8445\n",
      "val Loss: 0.6069 Acc: 0.7795 AUC: 0.8452\n",
      "\n",
      "Epoch 46/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7755 AUC: 0.8432\n",
      "val Loss: 0.6044 Acc: 0.7873 AUC: 0.8448\n",
      "\n",
      "Epoch 47/299\n",
      "----------\n",
      "train Loss: 0.6062 Acc: 0.7746 AUC: 0.8458\n",
      "val Loss: 0.6036 Acc: 0.7840 AUC: 0.8489\n",
      "\n",
      "Epoch 48/299\n",
      "----------\n",
      "train Loss: 0.6053 Acc: 0.7778 AUC: 0.8472\n",
      "val Loss: 0.6043 Acc: 0.7870 AUC: 0.8456\n",
      "\n",
      "Epoch 49/299\n",
      "----------\n",
      "train Loss: 0.6068 Acc: 0.7744 AUC: 0.8435\n",
      "val Loss: 0.6052 Acc: 0.7780 AUC: 0.8475\n",
      "\n",
      "Epoch 50/299\n",
      "----------\n",
      "train Loss: 0.6070 Acc: 0.7729 AUC: 0.8419\n",
      "val Loss: 0.6069 Acc: 0.7710 AUC: 0.8459\n",
      "\n",
      "Epoch 51/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7762 AUC: 0.8432\n",
      "val Loss: 0.6057 Acc: 0.7800 AUC: 0.8454\n",
      "\n",
      "Epoch 52/299\n",
      "----------\n",
      "train Loss: 0.6056 Acc: 0.7772 AUC: 0.8448\n",
      "val Loss: 0.6044 Acc: 0.7758 AUC: 0.8505\n",
      "\n",
      "Epoch 53/299\n",
      "----------\n",
      "train Loss: 0.6060 Acc: 0.7754 AUC: 0.8449\n",
      "val Loss: 0.6058 Acc: 0.7805 AUC: 0.8437\n",
      "\n",
      "Epoch 54/299\n",
      "----------\n",
      "train Loss: 0.6050 Acc: 0.7784 AUC: 0.8467\n",
      "val Loss: 0.6059 Acc: 0.7820 AUC: 0.8432\n",
      "\n",
      "Epoch 55/299\n",
      "----------\n",
      "train Loss: 0.6056 Acc: 0.7761 AUC: 0.8448\n",
      "val Loss: 0.6066 Acc: 0.7810 AUC: 0.8459\n",
      "\n",
      "Epoch 56/299\n",
      "----------\n",
      "train Loss: 0.6065 Acc: 0.7749 AUC: 0.8442\n",
      "val Loss: 0.6052 Acc: 0.7772 AUC: 0.8451\n",
      "\n",
      "Epoch 57/299\n",
      "----------\n",
      "train Loss: 0.6065 Acc: 0.7752 AUC: 0.8437\n",
      "val Loss: 0.6043 Acc: 0.7768 AUC: 0.8467\n",
      "\n",
      "Epoch 58/299\n",
      "----------\n",
      "train Loss: 0.6057 Acc: 0.7769 AUC: 0.8451\n",
      "val Loss: 0.6045 Acc: 0.7752 AUC: 0.8457\n",
      "\n",
      "Epoch 59/299\n",
      "----------\n",
      "train Loss: 0.6061 Acc: 0.7755 AUC: 0.8454\n",
      "val Loss: 0.6057 Acc: 0.7768 AUC: 0.8422\n",
      "\n",
      "Epoch 60/299\n",
      "----------\n",
      "train Loss: 0.6059 Acc: 0.7770 AUC: 0.8438\n",
      "val Loss: 0.6073 Acc: 0.7728 AUC: 0.8443\n",
      "\n",
      "Epoch 61/299\n",
      "----------\n",
      "train Loss: 0.6051 Acc: 0.7771 AUC: 0.8469\n",
      "val Loss: 0.6054 Acc: 0.7833 AUC: 0.8466\n",
      "\n",
      "Epoch 62/299\n",
      "----------\n",
      "train Loss: 0.6069 Acc: 0.7751 AUC: 0.8433\n",
      "val Loss: 0.6057 Acc: 0.7780 AUC: 0.8443\n",
      "\n",
      "Epoch 63/299\n",
      "----------\n",
      "train Loss: 0.6068 Acc: 0.7742 AUC: 0.8435\n",
      "val Loss: 0.6068 Acc: 0.7738 AUC: 0.8456\n",
      "\n",
      "Epoch 64/299\n",
      "----------\n",
      "train Loss: 0.6052 Acc: 0.7783 AUC: 0.8455\n",
      "val Loss: 0.6057 Acc: 0.7823 AUC: 0.8439\n",
      "\n",
      "Epoch 65/299\n",
      "----------\n",
      "train Loss: 0.6045 Acc: 0.7789 AUC: 0.8473\n",
      "val Loss: 0.6047 Acc: 0.7795 AUC: 0.8457\n",
      "\n",
      "Epoch 66/299\n",
      "----------\n",
      "train Loss: 0.6058 Acc: 0.7770 AUC: 0.8436\n",
      "val Loss: 0.6034 Acc: 0.7820 AUC: 0.8476\n",
      "\n",
      "Epoch 67/299\n",
      "----------\n",
      "train Loss: 0.6067 Acc: 0.7741 AUC: 0.8459\n",
      "val Loss: 0.6068 Acc: 0.7735 AUC: 0.8448\n",
      "\n",
      "Epoch 68/299\n",
      "----------\n",
      "train Loss: 0.6056 Acc: 0.7768 AUC: 0.8466\n",
      "val Loss: 0.6061 Acc: 0.7823 AUC: 0.8452\n",
      "\n",
      "Epoch 69/299\n",
      "----------\n",
      "train Loss: 0.6062 Acc: 0.7746 AUC: 0.8447\n",
      "val Loss: 0.6017 Acc: 0.7865 AUC: 0.8465\n",
      "\n",
      "Epoch 70/299\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0b100fbd3a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=300)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-4fc382028914>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                         \u001b[0moutput_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                         \u001b[0mlabel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "random_seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_set, va_set = torch.utils.data.random_split(dataset, [tra,val],generator=torch.Generator().manual_seed(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.DataLoader(tra_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_set = torch.utils.data.DataLoader(va_set, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.6652 Acc: 0.5969 AUC: 0.7425\n",
      "val Loss: 0.6138 Acc: 0.7512 AUC: 0.8601\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.6093 Acc: 0.7642 AUC: 0.8564\n",
      "val Loss: 0.6003 Acc: 0.7622 AUC: 0.8851\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.5999 Acc: 0.7816 AUC: 0.8693\n",
      "val Loss: 0.5959 Acc: 0.7915 AUC: 0.8821\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.5950 Acc: 0.7969 AUC: 0.8774\n",
      "val Loss: 0.5989 Acc: 0.8030 AUC: 0.8848\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.5916 Acc: 0.8074 AUC: 0.8864\n",
      "val Loss: 0.5895 Acc: 0.8133 AUC: 0.8953\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.5904 Acc: 0.8086 AUC: 0.8857\n",
      "val Loss: 0.5873 Acc: 0.8227 AUC: 0.8982\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.5875 Acc: 0.8134 AUC: 0.8884\n",
      "val Loss: 0.5916 Acc: 0.7963 AUC: 0.8877\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.5823 Acc: 0.8186 AUC: 0.8985\n",
      "val Loss: 0.5864 Acc: 0.8205 AUC: 0.8983\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.5806 Acc: 0.8306 AUC: 0.8998\n",
      "val Loss: 0.5859 Acc: 0.8240 AUC: 0.8998\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.5796 Acc: 0.8324 AUC: 0.9016\n",
      "val Loss: 0.5842 Acc: 0.8317 AUC: 0.9008\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.5799 Acc: 0.8288 AUC: 0.9020\n",
      "val Loss: 0.5846 Acc: 0.8243 AUC: 0.9015\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.5766 Acc: 0.8360 AUC: 0.9053\n",
      "val Loss: 0.5861 Acc: 0.8197 AUC: 0.8991\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.5772 Acc: 0.8377 AUC: 0.9055\n",
      "val Loss: 0.5845 Acc: 0.8317 AUC: 0.9001\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.5767 Acc: 0.8366 AUC: 0.9051\n",
      "val Loss: 0.5854 Acc: 0.8170 AUC: 0.9016\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.5750 Acc: 0.8427 AUC: 0.9066\n",
      "val Loss: 0.5820 Acc: 0.8285 AUC: 0.9012\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-500c55e1c7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=100)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-4fc382028914>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/domain_adapt_cxr-ilmJFro8/lib64/python3.6/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/domain_adapt_cxr-ilmJFro8/lib64/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/domain_adapt_cxr-ilmJFro8/lib64/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/domain_adapt_cxr-ilmJFro8/lib64/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    115\u001b[0m                   \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                   \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                   nesterov)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/domain_adapt_cxr-ilmJFro8/lib64/python3.6/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/diwenxu2/dataset_gan/mimic_10k_seed8_v3.ckpt'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if n>=1000:\n",
    "    n = str(int(n/1000))+'k'\n",
    "if m>=1000:\n",
    "    m = str(int(m/1000))+'k'\n",
    "weights_path = '/home/diwenxu2/dataset_gan/mimic_'+str(m)+'_seed'+str(random_seed)+'_v3.ckpt'\n",
    "torch.save(model_ft.state_dict(), weights_path)\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/diwenxu2/dataset_gan/chexpert_30k_seed8_v3.ckpt'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.load_state_dict(torch.load('covid_classifier.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/diwenxu2/xray_latent2im/model_Covid/stylegan_v2_xray_linear_lr0.0001_l2_w/images/w_1_seed12_Covid_max1.0_min0.0_sample3_0.64.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_ = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/diwenxu2/xray_latent2im/20k_images/'\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model,img_path):\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    transformed_img = transform_(image)\n",
    "    transformed_img = transformed_img.to('cuda')\n",
    "    image = transformed_img.unsqueeze(0).cuda()\n",
    "    output = model(image)\n",
    "    _,preds = torch.max(output,1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred(model,'/home/diwenxu2/xray_latent2im/model_Covid/stylegan_v2_xray_linear_lr0.0001_l2_w/images/org_img/w_1_seed12_Covid_max1.0_min0.0_sample2_0.01_org.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0\n",
    "for i in files[:1000]:\n",
    "    img_path = path+i\n",
    "    preds = pred(model,img_path)\n",
    "    if preds == 1:\n",
    "        ratio+=1\n",
    "ratio/=1000\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pred(model,path+files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = transform_(image)\n",
    "transformed_img = transformed_img.to('cuda')\n",
    "image = transformed_img.unsqueeze(0).cuda()\n",
    "output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/diwenxu2/xray_latent2im/model_Covid/stylegan_v2_xray_linear_lr0.0001_l2_w/images/w_1_seed12_Covid_max0.0_min0.0_sample4_0.23.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(img_path).convert('RGB')\n",
    "transformed_img = transform_(image)\n",
    "transformed_img = transformed_img.to('cuda')\n",
    "image = transformed_img.unsqueeze(0).cuda()\n",
    "output = model(image)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(img)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,preds = torch.max(res,1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_json = '/home/diwenxu2/Chexpert/config/example.json'\n",
    "with open(reg_json) as f:\n",
    "    cfg = edict(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "        ImageDataset(cfg.train_csv, cfg, mode='train'),\n",
    "        batch_size=batch_size, num_workers=12,\n",
    "        drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_header = dataloader_train.dataset._label_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dev = DataLoader(\n",
    "        ImageDataset(cfg.dev_csv, cfg, mode='dev'),\n",
    "        batch_size=batch_size, num_workers=4,\n",
    "        drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_header = dataloader_dev.dataset._label_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train':dataloader_train,'val':dataloader_dev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = len(dataloader_train)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.sigmoid(outputs[3].view(-1)).ge(0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(output, target, index, cfg, device):\n",
    "    for num_class in cfg.num_classes:\n",
    "        assert num_class == 1\n",
    "    target = target[:, index].view(-1)\n",
    "    pos_weight = torch.from_numpy(\n",
    "        np.array(cfg.pos_weight,\n",
    "                 dtype=np.float32)).to(device).type_as(target)\n",
    "    if cfg.batch_weight:\n",
    "        if target.sum() == 0:\n",
    "            loss = torch.tensor(0., requires_grad=True).to(device)\n",
    "        else:\n",
    "            weight = (target.size()[0] - target.sum()) / target.sum()\n",
    "            loss = F.binary_cross_entropy_with_logits(\n",
    "                output[:,index].view(-1), target, pos_weight=weight)\n",
    "    else:\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            output[:,index].view(-1), target, pos_weight=pos_weight[index])\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, device, num_epochs):\n",
    "    dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                loss = 0\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    for t in range(5):\n",
    "                        loss_t = get_loss(outputs, labels, t, cfg, device)\n",
    "                        loss += loss_t\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                preds = torch.sigmoid(outputs).ge(0.5).float()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)/(len(preds)*len(preds[0]))\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model, optimizer, exp_lr_scheduler,device,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), 'vgg19.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = models.vgg19(pretrained=False)\n",
    "mod = list(vgg19.classifier.children())\n",
    "mod.pop()\n",
    "mod.append(torch.nn.Linear(4096, 2))\n",
    "new_classifier = torch.nn.Sequential(*mod)\n",
    "vgg19.classifier = new_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg19 = nn.DataParallel(vgg19)\n",
    "vgg19.load_state_dict(torch.load('covid_classifier.ckpt'))\n",
    "vgg19 = vgg19.cuda().features.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "num_tasks = len(cfg.num_classes)\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader_train, 0)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].cuda(), data[1].cuda()\n",
    "        outputs = model(inputs)\n",
    "            \n",
    "        loss = 0\n",
    "        for t in range(num_tasks):\n",
    "            loss_t = get_loss(outputs, labels, t, cfg)\n",
    "            loss += loss_t\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('domain_adapt_cxr-ilmJFro8': pipenv)",
   "language": "python",
   "name": "python368jvsc74a57bd0d548e83b0b28ca71444171775b3c91f545236136598938699a1416c5ca8fe191"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
